{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2a1edd-7adb-4bbf-a672-fbfb84d14e32",
   "metadata": {},
   "source": [
    "# Scrape Linkedin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d7fc9e-da88-4ef3-9af4-85ef9ecd6e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linkedin-scraper==2.11.2\n"
     ]
    }
   ],
   "source": [
    "# Make sure we have installed the dependency\n",
    "! pip freeze | grep linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f755f7ef-09a8-4caa-809f-551ba6949eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linkedin_scraper import JobSearch, Job, actions\n",
    "from typing import List\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "import urllib\n",
    "from time import sleep\n",
    "\n",
    "def set_chrome_options() -> Options:\n",
    "    \"\"\"Sets chrome options for Selenium.\n",
    "    Chrome options for headless browser is enabled.\n",
    "    \"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_prefs = {}\n",
    "    chrome_options.experimental_options[\"prefs\"] = chrome_prefs\n",
    "    chrome_prefs[\"profile.default_content_settings\"] = {\"images\": 2}\n",
    "    return chrome_options\n",
    "\n",
    "class _JobSearch(JobSearch):\n",
    "    def __init__(self, final_url=None, **kwargs):\n",
    "        self.final_url = final_url\n",
    "        self.current_url = None\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def search(self, search_term: str, page_n) -> List[Job]:\n",
    "        if self.final_url is None:\n",
    "            self.current_url = os.path.join(self.base_url, \"search\") + f\"?keywords={urllib.parse.quote(search_term)}&refresh=true\"\n",
    "            self.driver.get(self.current_url)\n",
    "\n",
    "            # Get redirection URL\n",
    "            self.final_url = self.driver.current_url\n",
    "        else:\n",
    "            self.current_url = os.path.join(self.final_url, f\"&start={25*(page_n-1)}\")\n",
    "            self.driver.get(self.current_url)\n",
    "        \n",
    "        self.scroll_to_bottom()\n",
    "        self.focus()\n",
    "        sleep(self.WAIT_FOR_ELEMENT_TIMEOUT)\n",
    "\n",
    "        job_listing_class_name = \"jobs-search-results-list\"\n",
    "        job_listing = self.wait_for_element_to_load(name=job_listing_class_name)\n",
    "\n",
    "        self.scroll_class_name_element_to_page_percent(job_listing_class_name, 0.3)\n",
    "        self.focus()\n",
    "        sleep(self.WAIT_FOR_ELEMENT_TIMEOUT)\n",
    "\n",
    "        self.scroll_class_name_element_to_page_percent(job_listing_class_name, 0.6)\n",
    "        self.focus()\n",
    "        sleep(self.WAIT_FOR_ELEMENT_TIMEOUT)\n",
    "\n",
    "        self.scroll_class_name_element_to_page_percent(job_listing_class_name, 1)\n",
    "        self.focus()\n",
    "        sleep(self.WAIT_FOR_ELEMENT_TIMEOUT)\n",
    "\n",
    "        job_results = []\n",
    "        for job_card in self.wait_for_all_elements_to_load(name=\"job-card-list\", base=job_listing):\n",
    "            job = self.scrape_job_card(job_card)\n",
    "            job_results.append(job)\n",
    "        return job_results\n",
    "\n",
    "def are_same(job1: Job, job2: Job):\n",
    "    if job1.job_title == job2.job_title and job1.company == job2.company:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da612fd0-f5c4-4b3a-b2ee-578b132f471c",
   "metadata": {},
   "source": [
    "## 1. Scrape Job Search\n",
    "\n",
    "Scrape the first 20 pages of the search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771e66e2-2364-4cdb-b4f1-f2abb4ec7287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Logged in.\n"
     ]
    }
   ],
   "source": [
    "# Set up the lower-level services for scraping\n",
    "driver = webdriver.Chrome(options=set_chrome_options())\n",
    "actions.login(driver, os.environ[\"EMAIL\"], os.environ[\"PWORD\"]) # if email and password isnt given, it'll prompt in terminal\n",
    "print(\"... Logged in.\")\n",
    "job_search = _JobSearch(driver=driver, close_on_complete=False, scrape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d87d07e-659d-4abb-a058-e6d2c14e108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Searching jobs... Keyword: data; Page 1/22'\n",
      "'FINISHED PAGE: 1'\n",
      "'Searching jobs... Keyword: data; Page 2/22'\n",
      "'FINISHED PAGE: 2'\n",
      "'Searching jobs... Keyword: data; Page 3/22'\n",
      "'FINISHED PAGE: 3'\n",
      "'Searching jobs... Keyword: data; Page 4/22'\n",
      "'FINISHED PAGE: 4'\n",
      "'Searching jobs... Keyword: data; Page 5/22'\n",
      "'FINISHED PAGE: 5'\n",
      "'Searching jobs... Keyword: data; Page 6/22'\n",
      "'FINISHED PAGE: 6'\n",
      "'Searching jobs... Keyword: data; Page 7/22'\n",
      "'FINISHED PAGE: 7'\n",
      "'Searching jobs... Keyword: data; Page 8/22'\n",
      "'FINISHED PAGE: 8'\n",
      "'Searching jobs... Keyword: data; Page 9/22'\n",
      "'FINISHED PAGE: 9'\n",
      "'Searching jobs... Keyword: data; Page 10/22'\n",
      "'FINISHED PAGE: 10'\n",
      "'Searching jobs... Keyword: data; Page 11/22'\n",
      "'FINISHED PAGE: 11'\n",
      "'Searching jobs... Keyword: data; Page 12/22'\n",
      "'FINISHED PAGE: 12'\n",
      "'Searching jobs... Keyword: data; Page 13/22'\n",
      "'FINISHED PAGE: 13'\n",
      "'Searching jobs... Keyword: data; Page 14/22'\n",
      "'FINISHED PAGE: 14'\n",
      "'Searching jobs... Keyword: data; Page 15/22'\n",
      "'FINISHED PAGE: 15'\n",
      "'Searching jobs... Keyword: data; Page 16/22'\n",
      "'FINISHED PAGE: 16'\n",
      "'Searching jobs... Keyword: data; Page 17/22'\n",
      "'FINISHED PAGE: 17'\n",
      "'Searching jobs... Keyword: data; Page 18/22'\n",
      "'FINISHED PAGE: 18'\n",
      "'Searching jobs... Keyword: data; Page 19/22'\n",
      "'FINISHED PAGE: 19'\n",
      "'Searching jobs... Keyword: data; Page 20/22'\n",
      "'FINISHED PAGE: 20'\n",
      "'Searching jobs... Keyword: data; Page 21/22'\n",
      "'FINISHED PAGE: 21'\n",
      "'Searching jobs... Keyword: data; Page 22/22'\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 61\u001b[0m, in \u001b[0;36m_JobSearch.search\u001b[0;34m(self, search_term, page_n)\u001b[0m\n\u001b[1;32m     58\u001b[0m sleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWAIT_FOR_ELEMENT_TIMEOUT)\n\u001b[1;32m     60\u001b[0m job_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job_card \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_all_elements_to_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjob-card-list\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_listing\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     62\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscrape_job_card(job_card)\n\u001b[1;32m     63\u001b[0m     job_results\u001b[38;5;241m.\u001b[39mappend(job)\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/linkedin_scraper/objects.py:93\u001b[0m, in \u001b[0;36mScraper.wait_for_all_elements_to_load\u001b[0;34m(self, by, name, base)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for_all_elements_to_load\u001b[39m(\u001b[38;5;28mself\u001b[39m, by\u001b[38;5;241m=\u001b[39mBy\u001b[38;5;241m.\u001b[39mCLASS_NAME, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpv-top-card\u001b[39m\u001b[38;5;124m\"\u001b[39m, base\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     92\u001b[0m     base \u001b[38;5;241m=\u001b[39m base \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWAIT_FOR_ELEMENT_TIMEOUT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_all_elements_located\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/selenium/webdriver/support/wait.py:95\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_PAGES = 22\n",
    "SEARCH_KEYWORD = \"data\"\n",
    "\n",
    "jobs = []\n",
    "for page_n in range(1, N_PAGES+1):\n",
    "    pprint(f\"Searching jobs... Keyword: {SEARCH_KEYWORD}; Page {page_n}/{N_PAGES}\")\n",
    "    new_batch = job_search.search(SEARCH_KEYWORD, page_n)\n",
    "\n",
    "    # Check if the new batch of jobs are duplicates, \n",
    "    # which means we have gone through all the pages and should quit scraping.\n",
    "    if jobs and are_same(new_batch[0], jobs[0]):\n",
    "        pprint(\"Found duplicate results! All the pages have been scraped. Quiting...\")\n",
    "        break\n",
    "        \n",
    "    jobs.extend(new_batch)\n",
    "    pprint(f\"FINISHED PAGE: {page_n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54ca956d-a4cb-443d-8d9d-7bbc96e6e4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "500ab9ca-d346-4b90-abb0-fafdffefca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save today's crawl temporarily\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "fname = f\"helsinki_data_jobs_{current_date}.pkl\"\n",
    "with open(f\"../data/{fname}\", \"wb\") as f:\n",
    "    dicted_jobs = [job.to_dict() for job in jobs]\n",
    "    pickle.dump(dicted_jobs,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22f02c2-cd94-4e16-bb3e-3c3c4b761913",
   "metadata": {},
   "source": [
    "## 2. Scrape job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17c1166-5c4d-4ee4-a684-10c0535f32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from linkedin_scraper import Job, actions\n",
    "\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class _Job(Job):\n",
    "    def __init__(self, **kwargs):\n",
    "       self.job_title = \"\"\n",
    "       self.required_skills = \"\"\n",
    "       self.job_type_1 = \"\"\n",
    "       self.job_type_2 = \"\"\n",
    " \n",
    "       super().__init__(**kwargs)\n",
    "    \n",
    "    def scrape_logged_in(self, close_on_complete=True):\n",
    "        driver = self.driver\n",
    "        \n",
    "        driver.get(self.linkedin_url)\n",
    "        self.focus()\n",
    "        self.job_title = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'jobs-unified-top-card__job-title')]\").text.strip()\n",
    "        self.company = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-jobs-unified-top-card__primary-description')]//a[1]\").text.strip()\n",
    "        self.company_linkedin_url = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-jobs-unified-top-card__primary-description')]//a\").get_attribute(\"href\")\n",
    "        self.location = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-jobs-unified-top-card__primary-description')]//*\").text.strip()\n",
    "        self.posted_date = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-jobs-unified-top-card__primary-description')]//span[3]\").text.strip()\n",
    "        self.job_type_1 = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'ui-label ui-label--accent-3 text-body-small')]/span\").text.strip()\n",
    "        self.job_description = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'jobs-description')]\").text.strip()\n",
    "        \n",
    "        try:\n",
    "            self.required_skills = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-how-you-match__skills-item')][1]//a\").text.strip()\n",
    "        except TimeoutException as e:\n",
    "            logger.error(str(e))\n",
    "\n",
    "        try:\n",
    "            self.required_skills += self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-how-you-match__skills-item')][2]//a\").text.strip()\n",
    "        except TimeoutException as e:\n",
    "            logger.error(str(e))\n",
    "\n",
    "        try:\n",
    "            self.job_type_2 = self.wait_for_element_to_load(by=By.XPATH, name=\"(//*[contains(@class, 'ui-label ui-label--accent-3 text-body-small')])[2]/span\").text.strip()\n",
    "        except TimeoutException:\n",
    "            self.job_type_2 = \"\"\n",
    "            \n",
    "        try:\n",
    "            self.applicant_count = self.wait_for_element_to_load(by=By.XPATH, name=\"jobs-unified-top-card__applicant-count\").text.strip()\n",
    "        except TimeoutException:\n",
    "            self.applicant_count = 0\n",
    "        \n",
    "        try:\n",
    "            self.benefits = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'salary-main-rail-card')]\").text.strip()\n",
    "        except TimeoutException:\n",
    "            self.benefits = \"\"\n",
    "\n",
    "        if close_on_complete:\n",
    "            driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0690bf7-4c55-434f-a72b-fae89fd21906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "import urllib\n",
    "from time import sleep\n",
    "\n",
    "def set_chrome_options() -> Options:\n",
    "    \"\"\"Sets chrome options for Selenium.\n",
    "    Chrome options for headless browser is enabled.\n",
    "    \"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_prefs = {}\n",
    "    chrome_options.experimental_options[\"prefs\"] = chrome_prefs\n",
    "    chrome_prefs[\"profile.default_content_settings\"] = {\"images\": 2}\n",
    "    return chrome_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b010a69b-bf8d-434e-ba07-641b09ff211c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Logged in.\n"
     ]
    }
   ],
   "source": [
    "# Set up low-level servies for scraping\n",
    "driver = webdriver.Chrome(options=set_chrome_options())\n",
    "actions.login(driver, os.environ[\"EMAIL\"], os.environ[\"PWORD\"]) \n",
    "print(\"... Logged in.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc5236-f815-4a94-b6b4-f0b368132f1e",
   "metadata": {},
   "source": [
    "Ignore the error logs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b8e6e6-ed7c-4f70-8f48-8e5b463c681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/helsinki_data_jobs_2023-10-22.pkl\", \"rb\") as f:\n",
    "    jobs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10b00c9-d1d6-4723-89a1-7823fd0f4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 160/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n",
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: stale element not found\n  (Session info: headless chrome=114.0.5735.90); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n#0 0x55fd0c4c74e3 <unknown>\n#1 0x55fd0c1f6c76 <unknown>\n#2 0x55fd0c1fb53c <unknown>\n#3 0x55fd0c1fc97e <unknown>\n#4 0x55fd0c1fca4c <unknown>\n#5 0x55fd0c22d922 <unknown>\n#6 0x55fd0c252012 <unknown>\n#7 0x55fd0c228b03 <unknown>\n#8 0x55fd0c2521de <unknown>\n#9 0x55fd0c26a30e <unknown>\n#10 0x55fd0c251de3 <unknown>\n#11 0x55fd0c2272dd <unknown>\n#12 0x55fd0c22834e <unknown>\n#13 0x55fd0c4873e4 <unknown>\n#14 0x55fd0c48b3d7 <unknown>\n#15 0x55fd0c495b20 <unknown>\n#16 0x55fd0c48c023 <unknown>\n#17 0x55fd0c45a1aa <unknown>\n#18 0x55fd0c4b06b8 <unknown>\n#19 0x55fd0c4b0847 <unknown>\n#20 0x55fd0c4c0243 <unknown>\n#21 0x7fd44c094ac3 <unknown>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:6\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m, in \u001b[0;36m_Job.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_type_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_type_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/linkedin_scraper/jobs.py:40\u001b[0m, in \u001b[0;36mJob.__init__\u001b[0;34m(self, linkedin_url, job_title, company, company_linkedin_url, location, posted_date, applicant_count, job_description, benefits, driver, close_on_complete, scrape)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbenefits \u001b[38;5;241m=\u001b[39m benefits\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scrape:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclose_on_complete\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/linkedin_scraper/jobs.py:47\u001b[0m, in \u001b[0;36mJob.scrape\u001b[0;34m(self, close_on_complete)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape\u001b[39m(\u001b[38;5;28mself\u001b[39m, close_on_complete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_signed_in():\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_logged_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclose_on_complete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclose_on_complete\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis part is not implemented yet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 55\u001b[0m, in \u001b[0;36m_Job.scrape_logged_in\u001b[0;34m(self, close_on_complete)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapplicant_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbenefits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_element_to_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//*[contains(@class, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalary-main-rail-card\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutException:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbenefits \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:89\u001b[0m, in \u001b[0;36mWebElement.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The text of the element.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_ELEMENT_TEXT\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:394\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    392\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    393\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:344\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    342\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: stale element not found\n  (Session info: headless chrome=114.0.5735.90); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n#0 0x55fd0c4c74e3 <unknown>\n#1 0x55fd0c1f6c76 <unknown>\n#2 0x55fd0c1fb53c <unknown>\n#3 0x55fd0c1fc97e <unknown>\n#4 0x55fd0c1fca4c <unknown>\n#5 0x55fd0c22d922 <unknown>\n#6 0x55fd0c252012 <unknown>\n#7 0x55fd0c228b03 <unknown>\n#8 0x55fd0c2521de <unknown>\n#9 0x55fd0c26a30e <unknown>\n#10 0x55fd0c251de3 <unknown>\n#11 0x55fd0c2272dd <unknown>\n#12 0x55fd0c22834e <unknown>\n#13 0x55fd0c4873e4 <unknown>\n#14 0x55fd0c48b3d7 <unknown>\n#15 0x55fd0c495b20 <unknown>\n#16 0x55fd0c48c023 <unknown>\n#17 0x55fd0c45a1aa <unknown>\n#18 0x55fd0c4b06b8 <unknown>\n#19 0x55fd0c4b0847 <unknown>\n#20 0x55fd0c4c0243 <unknown>\n#21 0x7fd44c094ac3 <unknown>\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import sleep\n",
    "\n",
    "N_JOBS = len(jobs)\n",
    "\n",
    "crawled_jobs = []\n",
    "for i, job in enumerate(jobs):\n",
    "    print(f\"Crawling... Jobs {i+1}/{N_JOBS}\")\n",
    "    _crawled_job = _Job(linkedin_url=job.get(\"linkedin_url\"), driver=driver, close_on_complete=False, scrape=True)\n",
    "    crawled_jobs.append(_crawled_job)\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cad0dbf8-cba2-42bc-a496-57345dde2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "260db594-e6f7-4ebc-9294-e132e9ae5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crawled_jobs = pd.DataFrame([vars(job) for job in crawled_jobs]).drop(columns=[\"driver\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc2d9665-a746-4a98-a1f2-7446de35ac9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>required_skills</th>\n",
       "      <th>job_type_1</th>\n",
       "      <th>job_type_2</th>\n",
       "      <th>linkedin_url</th>\n",
       "      <th>company</th>\n",
       "      <th>company_linkedin_url</th>\n",
       "      <th>location</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>applicant_count</th>\n",
       "      <th>job_description</th>\n",
       "      <th>benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWE Scientist / Epidemiologist</td>\n",
       "      <td>Customer Relationship Management (CRM), Epidem...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3737909849/...</td>\n",
       "      <td>MedEngine</td>\n",
       "      <td>https://www.linkedin.com/company/medengine/life</td>\n",
       "      <td>MedEngine · Helsinki, Uusimaa, Finland  1 week...</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nMedEngine is a digitally minded...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineering, Git, Python (Programming Lan...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3736532279/...</td>\n",
       "      <td>Suomen Palloliitto - Football Association of F...</td>\n",
       "      <td>https://www.linkedin.com/company/football-asso...</td>\n",
       "      <td>Suomen Palloliitto - Football Association of F...</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nDATA ENGINEER\\n\\nSUOMEN PALLOLI...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Game Analyst</td>\n",
       "      <td>Analytical Skills, Data Analysis, Economics, M...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3717037977/...</td>\n",
       "      <td>Next Games, A Netflix Game Studio</td>\n",
       "      <td>https://www.linkedin.com/company/next-games/life</td>\n",
       "      <td>Next Games, A Netflix Game Studio · Helsinki, ...</td>\n",
       "      <td>Reposted  6 days ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nNext Games is a Netflix Game St...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Analysis, Data Science, Machine Learning,...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3735986015/...</td>\n",
       "      <td>MedEngine</td>\n",
       "      <td>https://www.linkedin.com/company/medengine/life</td>\n",
       "      <td>MedEngine · Helsinki, Uusimaa, Finland  1 week...</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nMedEngine is a digitally minded...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science - Machine Learning Engineer</td>\n",
       "      <td>Artificial Intelligence (AI), Computer Science...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3629670334/...</td>\n",
       "      <td>Wolt</td>\n",
       "      <td>https://www.linkedin.com/company/wolt-oy/life</td>\n",
       "      <td>Wolt · Helsinki, Uusimaa, Finland Reposted  2 ...</td>\n",
       "      <td>Reposted  2 weeks ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nJob Description\\n\\nTeam purpose...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Senior Privacy Counsel</td>\n",
       "      <td>Communication, Data Privacy, General Data Prot...</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3706022536/...</td>\n",
       "      <td>Wolt</td>\n",
       "      <td>https://www.linkedin.com/company/wolt-oy/life</td>\n",
       "      <td>Wolt · Helsinki, Uusimaa, Finland Reposted  1 ...</td>\n",
       "      <td>Reposted  1 week ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nJob Description\\n\\nAre you an e...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Kotlin Backend Engineer, Merchant Group</td>\n",
       "      <td>Back-End Web Development and Software Developm...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3742731278/...</td>\n",
       "      <td>Wolt</td>\n",
       "      <td>https://www.linkedin.com/company/wolt-oy/life</td>\n",
       "      <td>Wolt · Helsinki, Uusimaa, Finland  3 days ago ...</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nJob Description\\n\\nWe’re lookin...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Doctoral Researcher in Bacterial Temperature A...</td>\n",
       "      <td>Research ProjectsAdaptation, Bioinformatics, B...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td></td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3741784865/...</td>\n",
       "      <td>University of Helsinki</td>\n",
       "      <td>https://www.linkedin.com/company/university-of...</td>\n",
       "      <td>University of Helsinki · Helsinki, Uusimaa, Fi...</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nThe University of Helsinki is o...</td>\n",
       "      <td>Benefits found in job post\\nMedical insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Cloud Service Manager</td>\n",
       "      <td>Cloud Computing and EnglishFostering inclusivi...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3727734994/...</td>\n",
       "      <td>OpenText</td>\n",
       "      <td>https://www.linkedin.com/company/opentext/life</td>\n",
       "      <td>OpenText · Tampere, Pirkanmaa, Finland  2 week...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nOpenText - The Information Comp...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Biostatistician and Aquatic Animal Modeler (Re...</td>\n",
       "      <td>Aquaculture, Bayesian, Bayesian statistics, Bi...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td></td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3735705041/...</td>\n",
       "      <td>Cargill</td>\n",
       "      <td>https://www.linkedin.com/company/cargill/life</td>\n",
       "      <td>Cargill · Helsinki, Uusimaa, Finland Reposted ...</td>\n",
       "      <td>Reposted  2 weeks ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nWant to build a stronger, more ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title  \\\n",
       "0                       RWE Scientist / Epidemiologist   \n",
       "1                                        Data Engineer   \n",
       "2                                  Senior Game Analyst   \n",
       "3                                       Data Scientist   \n",
       "4             Data Science - Machine Learning Engineer   \n",
       "..                                                 ...   \n",
       "229                             Senior Privacy Counsel   \n",
       "230            Kotlin Backend Engineer, Merchant Group   \n",
       "231  Doctoral Researcher in Bacterial Temperature A...   \n",
       "232                              Cloud Service Manager   \n",
       "233  Biostatistician and Aquatic Animal Modeler (Re...   \n",
       "\n",
       "                                       required_skills job_type_1 job_type_2  \\\n",
       "0    Customer Relationship Management (CRM), Epidem...     Hybrid  Full-time   \n",
       "1    Data Engineering, Git, Python (Programming Lan...     Hybrid  Full-time   \n",
       "2    Analytical Skills, Data Analysis, Economics, M...     Hybrid  Full-time   \n",
       "3    Data Analysis, Data Science, Machine Learning,...     Hybrid  Full-time   \n",
       "4    Artificial Intelligence (AI), Computer Science...     Remote  Full-time   \n",
       "..                                                 ...        ...        ...   \n",
       "229  Communication, Data Privacy, General Data Prot...    On-site  Full-time   \n",
       "230  Back-End Web Development and Software Developm...     Hybrid  Full-time   \n",
       "231  Research ProjectsAdaptation, Bioinformatics, B...  Full-time              \n",
       "232  Cloud Computing and EnglishFostering inclusivi...     Hybrid  Full-time   \n",
       "233  Aquaculture, Bayesian, Bayesian statistics, Bi...  Full-time              \n",
       "\n",
       "                                          linkedin_url  \\\n",
       "0    https://www.linkedin.com/jobs/view/3737909849/...   \n",
       "1    https://www.linkedin.com/jobs/view/3736532279/...   \n",
       "2    https://www.linkedin.com/jobs/view/3717037977/...   \n",
       "3    https://www.linkedin.com/jobs/view/3735986015/...   \n",
       "4    https://www.linkedin.com/jobs/view/3629670334/...   \n",
       "..                                                 ...   \n",
       "229  https://www.linkedin.com/jobs/view/3706022536/...   \n",
       "230  https://www.linkedin.com/jobs/view/3742731278/...   \n",
       "231  https://www.linkedin.com/jobs/view/3741784865/...   \n",
       "232  https://www.linkedin.com/jobs/view/3727734994/...   \n",
       "233  https://www.linkedin.com/jobs/view/3735705041/...   \n",
       "\n",
       "                                               company  \\\n",
       "0                                            MedEngine   \n",
       "1    Suomen Palloliitto - Football Association of F...   \n",
       "2                    Next Games, A Netflix Game Studio   \n",
       "3                                            MedEngine   \n",
       "4                                                 Wolt   \n",
       "..                                                 ...   \n",
       "229                                               Wolt   \n",
       "230                                               Wolt   \n",
       "231                             University of Helsinki   \n",
       "232                                           OpenText   \n",
       "233                                            Cargill   \n",
       "\n",
       "                                  company_linkedin_url  \\\n",
       "0      https://www.linkedin.com/company/medengine/life   \n",
       "1    https://www.linkedin.com/company/football-asso...   \n",
       "2     https://www.linkedin.com/company/next-games/life   \n",
       "3      https://www.linkedin.com/company/medengine/life   \n",
       "4        https://www.linkedin.com/company/wolt-oy/life   \n",
       "..                                                 ...   \n",
       "229      https://www.linkedin.com/company/wolt-oy/life   \n",
       "230      https://www.linkedin.com/company/wolt-oy/life   \n",
       "231  https://www.linkedin.com/company/university-of...   \n",
       "232     https://www.linkedin.com/company/opentext/life   \n",
       "233      https://www.linkedin.com/company/cargill/life   \n",
       "\n",
       "                                              location            posted_date  \\\n",
       "0    MedEngine · Helsinki, Uusimaa, Finland  1 week...             1 week ago   \n",
       "1    Suomen Palloliitto - Football Association of F...             1 week ago   \n",
       "2    Next Games, A Netflix Game Studio · Helsinki, ...   Reposted  6 days ago   \n",
       "3    MedEngine · Helsinki, Uusimaa, Finland  1 week...             1 week ago   \n",
       "4    Wolt · Helsinki, Uusimaa, Finland Reposted  2 ...  Reposted  2 weeks ago   \n",
       "..                                                 ...                    ...   \n",
       "229  Wolt · Helsinki, Uusimaa, Finland Reposted  1 ...   Reposted  1 week ago   \n",
       "230  Wolt · Helsinki, Uusimaa, Finland  3 days ago ...             3 days ago   \n",
       "231  University of Helsinki · Helsinki, Uusimaa, Fi...             5 days ago   \n",
       "232  OpenText · Tampere, Pirkanmaa, Finland  2 week...            2 weeks ago   \n",
       "233  Cargill · Helsinki, Uusimaa, Finland Reposted ...  Reposted  2 weeks ago   \n",
       "\n",
       "     applicant_count                                    job_description  \\\n",
       "0                  0  About the job\\nMedEngine is a digitally minded...   \n",
       "1                  0  About the job\\nDATA ENGINEER\\n\\nSUOMEN PALLOLI...   \n",
       "2                  0  About the job\\nNext Games is a Netflix Game St...   \n",
       "3                  0  About the job\\nMedEngine is a digitally minded...   \n",
       "4                  0  About the job\\nJob Description\\n\\nTeam purpose...   \n",
       "..               ...                                                ...   \n",
       "229                0  About the job\\nJob Description\\n\\nAre you an e...   \n",
       "230                0  About the job\\nJob Description\\n\\nWe’re lookin...   \n",
       "231                0  About the job\\nThe University of Helsinki is o...   \n",
       "232                0  About the job\\nOpenText - The Information Comp...   \n",
       "233                0  About the job\\nWant to build a stronger, more ...   \n",
       "\n",
       "                                          benefits  \n",
       "0                                                   \n",
       "1                                                   \n",
       "2                                                   \n",
       "3                                                   \n",
       "4                                                   \n",
       "..                                             ...  \n",
       "229                                                 \n",
       "230                                                 \n",
       "231  Benefits found in job post\\nMedical insurance  \n",
       "232                                                 \n",
       "233                                                 \n",
       "\n",
       "[234 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crawled_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bf2bda0-7b3c-425d-87a4-0420c1e45d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crawled_jobs.to_csv(\"../data/crawled_jobs_1-236_checkpoint.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568898a5-df54-4afa-85ff-3b858f901e30",
   "metadata": {},
   "source": [
    "### 2.1 Continue from the failed point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50eff973-e5db-40c0-9a73-24e02e836e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 194/313\n",
      "Crawling... Jobs 195/313\n",
      "Crawling... Jobs 196/313\n",
      "Crawling... Jobs 197/313\n",
      "Crawling... Jobs 198/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 199/313\n",
      "Crawling... Jobs 200/313\n",
      "Crawling... Jobs 201/313\n",
      "Crawling... Jobs 202/313\n",
      "Crawling... Jobs 203/313\n",
      "Crawling... Jobs 204/313\n",
      "Crawling... Jobs 205/313\n",
      "Crawling... Jobs 206/313\n",
      "Crawling... Jobs 207/313\n",
      "Crawling... Jobs 208/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 209/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 210/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 211/313\n",
      "Crawling... Jobs 212/313\n",
      "Crawling... Jobs 213/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 214/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 215/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n",
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 216/313\n",
      "Crawling... Jobs 217/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 218/313\n",
      "Crawling... Jobs 219/313\n",
      "Crawling... Jobs 220/313\n",
      "Crawling... Jobs 221/313\n",
      "Crawling... Jobs 222/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 223/313\n",
      "Crawling... Jobs 224/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 225/313\n",
      "Crawling... Jobs 226/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 227/313\n",
      "Crawling... Jobs 228/313\n",
      "Crawling... Jobs 229/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 230/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 231/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 232/313\n",
      "Crawling... Jobs 233/313\n",
      "Crawling... Jobs 234/313\n",
      "Crawling... Jobs 235/313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55fd0c4c74e3 <unknown>\n",
      "#1 0x55fd0c1f6c76 <unknown>\n",
      "#2 0x55fd0c232c96 <unknown>\n",
      "#3 0x55fd0c232dc1 <unknown>\n",
      "#4 0x55fd0c26c7f4 <unknown>\n",
      "#5 0x55fd0c25203d <unknown>\n",
      "#6 0x55fd0c26a30e <unknown>\n",
      "#7 0x55fd0c251de3 <unknown>\n",
      "#8 0x55fd0c2272dd <unknown>\n",
      "#9 0x55fd0c22834e <unknown>\n",
      "#10 0x55fd0c4873e4 <unknown>\n",
      "#11 0x55fd0c48b3d7 <unknown>\n",
      "#12 0x55fd0c495b20 <unknown>\n",
      "#13 0x55fd0c48c023 <unknown>\n",
      "#14 0x55fd0c45a1aa <unknown>\n",
      "#15 0x55fd0c4b06b8 <unknown>\n",
      "#16 0x55fd0c4b0847 <unknown>\n",
      "#17 0x55fd0c4c0243 <unknown>\n",
      "#18 0x7fd44c094ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 236/313\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n#0 0x55fd0c4c74e3 <unknown>\n#1 0x55fd0c1f6c76 <unknown>\n#2 0x55fd0c232c96 <unknown>\n#3 0x55fd0c232dc1 <unknown>\n#4 0x55fd0c26c7f4 <unknown>\n#5 0x55fd0c25203d <unknown>\n#6 0x55fd0c26a30e <unknown>\n#7 0x55fd0c251de3 <unknown>\n#8 0x55fd0c2272dd <unknown>\n#9 0x55fd0c22834e <unknown>\n#10 0x55fd0c4873e4 <unknown>\n#11 0x55fd0c48b3d7 <unknown>\n#12 0x55fd0c495b20 <unknown>\n#13 0x55fd0c48c023 <unknown>\n#14 0x55fd0c45a1aa <unknown>\n#15 0x55fd0c4b06b8 <unknown>\n#16 0x55fd0c4b0847 <unknown>\n#17 0x55fd0c4c0243 <unknown>\n#18 0x7fd44c094ac3 <unknown>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrawling... Jobs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_JOBS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m _crawled_job \u001b[38;5;241m=\u001b[39m \u001b[43m_Job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinkedin_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlinkedin_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_on_complete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscrape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m crawled_jobs\u001b[38;5;241m.\u001b[39mappend(_crawled_job)\n\u001b[1;32m     12\u001b[0m sleep(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m, in \u001b[0;36m_Job.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_type_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_type_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/linkedin_scraper/jobs.py:40\u001b[0m, in \u001b[0;36mJob.__init__\u001b[0;34m(self, linkedin_url, job_title, company, company_linkedin_url, location, posted_date, applicant_count, job_description, benefits, driver, close_on_complete, scrape)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbenefits \u001b[38;5;241m=\u001b[39m benefits\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scrape:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclose_on_complete\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/linkedin_scraper/jobs.py:47\u001b[0m, in \u001b[0;36mJob.scrape\u001b[0;34m(self, close_on_complete)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape\u001b[39m(\u001b[38;5;28mself\u001b[39m, close_on_complete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_signed_in():\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_logged_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclose_on_complete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclose_on_complete\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis part is not implemented yet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36m_Job.scrape_logged_in\u001b[0;34m(self, close_on_complete)\u001b[0m\n\u001b[1;32m     24\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinkedin_url)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfocus()\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_element_to_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//*[contains(@class, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjobs-unified-top-card__job-title\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompany \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_for_element_to_load(by\u001b[38;5;241m=\u001b[39mBy\u001b[38;5;241m.\u001b[39mXPATH, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//*[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob-details-jobs-unified-top-card__primary-description\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]//a[1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompany_linkedin_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_for_element_to_load(by\u001b[38;5;241m=\u001b[39mBy\u001b[38;5;241m.\u001b[39mXPATH, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//*[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob-details-jobs-unified-top-card__primary-description\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]//a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/linkedin_scraper/objects.py:82\u001b[0m, in \u001b[0;36mScraper.wait_for_element_to_load\u001b[0;34m(self, by, name, base)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for_element_to_load\u001b[39m(\u001b[38;5;28mself\u001b[39m, by\u001b[38;5;241m=\u001b[39mBy\u001b[38;5;241m.\u001b[39mCLASS_NAME, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpv-top-card\u001b[39m\u001b[38;5;124m\"\u001b[39m, base\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     81\u001b[0m     base \u001b[38;5;241m=\u001b[39m base \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWAIT_FOR_ELEMENT_TIMEOUT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/selenium/webdriver/support/wait.py:95\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n#0 0x55fd0c4c74e3 <unknown>\n#1 0x55fd0c1f6c76 <unknown>\n#2 0x55fd0c232c96 <unknown>\n#3 0x55fd0c232dc1 <unknown>\n#4 0x55fd0c26c7f4 <unknown>\n#5 0x55fd0c25203d <unknown>\n#6 0x55fd0c26a30e <unknown>\n#7 0x55fd0c251de3 <unknown>\n#8 0x55fd0c2272dd <unknown>\n#9 0x55fd0c22834e <unknown>\n#10 0x55fd0c4873e4 <unknown>\n#11 0x55fd0c48b3d7 <unknown>\n#12 0x55fd0c495b20 <unknown>\n#13 0x55fd0c48c023 <unknown>\n#14 0x55fd0c45a1aa <unknown>\n#15 0x55fd0c4b06b8 <unknown>\n#16 0x55fd0c4b0847 <unknown>\n#17 0x55fd0c4c0243 <unknown>\n#18 0x7fd44c094ac3 <unknown>\n"
     ]
    }
   ],
   "source": [
    "# Continue\n",
    "\n",
    "CONTINUE_FROM = 161\n",
    "\n",
    "for i, job in enumerate(jobs):\n",
    "    if i+1<CONTINUE_FROM:\n",
    "        continue\n",
    "        \n",
    "    print(f\"Crawling... Jobs {i+1}/{N_JOBS}\")\n",
    "    _crawled_job = _Job(linkedin_url=job.get(\"linkedin_url\"), driver=driver, close_on_complete=False, scrape=True)\n",
    "    crawled_jobs.append(_crawled_job)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb0d8b-2cb2-4217-ab99-6ece5a995d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
