{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2a1edd-7adb-4bbf-a672-fbfb84d14e32",
   "metadata": {},
   "source": [
    "# Scrape Linkedin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d7fc9e-da88-4ef3-9af4-85ef9ecd6e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linkedin-scraper==2.11.2\n"
     ]
    }
   ],
   "source": [
    "# Make sure we have installed the dependency\n",
    "! pip freeze | grep linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50695a9e-6b21-44db-825b-922a213bbd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Chrome 114.0.5735.90 \n"
     ]
    }
   ],
   "source": [
    "! google-chrome-stable --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f755f7ef-09a8-4caa-809f-551ba6949eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linkedin_scraper import JobSearch, Job, actions\n",
    "from typing import List\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "import urllib\n",
    "from time import sleep\n",
    "\n",
    "def set_chrome_options() -> Options:\n",
    "    \"\"\"Sets chrome options for Selenium.\n",
    "    Chrome options for headless browser is enabled.\n",
    "    \"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_prefs = {}\n",
    "    chrome_options.experimental_options[\"prefs\"] = chrome_prefs\n",
    "    chrome_prefs[\"profile.default_content_settings\"] = {\"images\": 2}\n",
    "    return chrome_options\n",
    "\n",
    "class _JobSearch(JobSearch):\n",
    "    def __init__(self, final_url=None, **kwargs):\n",
    "        self.final_url = final_url\n",
    "        self.current_url = None\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def search(self, search_term: str, page_n) -> List[Job]:\n",
    "        if self.final_url is None:\n",
    "            self.current_url = os.path.join(self.base_url, \"search\") + f\"?keywords={urllib.parse.quote(search_term)}&refresh=true\"\n",
    "            self.driver.get(self.current_url)\n",
    "\n",
    "            # Get redirection URL\n",
    "            self.final_url = self.driver.current_url\n",
    "        else:\n",
    "            self.current_url = os.path.join(self.final_url, f\"&start={25*(page_n-1)}\")\n",
    "            self.driver.get(self.current_url)\n",
    "        \n",
    "        self.scroll_to_bottom()\n",
    "        self.focus()\n",
    "        sleep(self.WAIT_FOR_ELEMENT_TIMEOUT)\n",
    "\n",
    "        job_listing_class_name = \"jobs-search-results-list\"\n",
    "        job_listing = self.wait_for_element_to_load(name=job_listing_class_name)\n",
    "\n",
    "        self.scroll_class_name_element_to_page_percent(job_listing_class_name, 0.3)\n",
    "        self.focus()\n",
    "        sleep(self.WAIT_FOR_ELEMENT_TIMEOUT)\n",
    "\n",
    "        self.scroll_class_name_element_to_page_percent(job_listing_class_name, 0.6)\n",
    "        self.focus()\n",
    "        sleep(self.WAIT_FOR_ELEMENT_TIMEOUT)\n",
    "\n",
    "        self.scroll_class_name_element_to_page_percent(job_listing_class_name, 1)\n",
    "        self.focus()\n",
    "        sleep(self.WAIT_FOR_ELEMENT_TIMEOUT)\n",
    "\n",
    "        job_results = []\n",
    "        for job_card in self.wait_for_all_elements_to_load(name=\"job-card-list\", base=job_listing):\n",
    "            job = self.scrape_job_card(job_card)\n",
    "            job_results.append(job)\n",
    "        return job_results\n",
    "\n",
    "def are_same(job1: Job, job2: Job):\n",
    "    if job1.job_title == job2.job_title and job1.company == job2.company:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da612fd0-f5c4-4b3a-b2ee-578b132f471c",
   "metadata": {},
   "source": [
    "## 1. Scrape Job Search\n",
    "\n",
    "Scrape the first 50 pages of the search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771e66e2-2364-4cdb-b4f1-f2abb4ec7287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Logged in.\n"
     ]
    }
   ],
   "source": [
    "# Set up the lower-level services for scraping\n",
    "driver = webdriver.Chrome(options=set_chrome_options())\n",
    "actions.login(driver, os.environ[\"EMAIL\"], os.environ[\"PWORD\"]) # if email and password isnt given, it'll prompt in terminal\n",
    "print(\"... Logged in.\")\n",
    "job_search = _JobSearch(driver=driver, close_on_complete=False, scrape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d87d07e-659d-4abb-a058-e6d2c14e108e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'FINISHED PAGE: 11'\n",
      "'Searching jobs... Keyword: data; Page 12/50'\n",
      "'FINISHED PAGE: 12'\n",
      "'Searching jobs... Keyword: data; Page 13/50'\n",
      "'FINISHED PAGE: 13'\n",
      "'Searching jobs... Keyword: data; Page 14/50'\n",
      "'FINISHED PAGE: 14'\n",
      "'Searching jobs... Keyword: data; Page 15/50'\n",
      "'FINISHED PAGE: 15'\n",
      "'Searching jobs... Keyword: data; Page 16/50'\n",
      "'FINISHED PAGE: 16'\n",
      "'Searching jobs... Keyword: data; Page 17/50'\n",
      "'FINISHED PAGE: 17'\n",
      "'Searching jobs... Keyword: data; Page 18/50'\n",
      "'FINISHED PAGE: 18'\n",
      "'Searching jobs... Keyword: data; Page 19/50'\n",
      "'FINISHED PAGE: 19'\n",
      "'Searching jobs... Keyword: data; Page 20/50'\n",
      "'FINISHED PAGE: 20'\n",
      "'Searching jobs... Keyword: data; Page 21/50'\n",
      "'FINISHED PAGE: 21'\n",
      "'Searching jobs... Keyword: data; Page 22/50'\n",
      "'FINISHED PAGE: 22'\n",
      "'Searching jobs... Keyword: data; Page 23/50'\n",
      "'SKIPPED PAGE: 23'\n",
      "'Searching jobs... Keyword: data; Page 24/50'\n",
      "'SKIPPED PAGE: 24'\n",
      "'Searching jobs... Keyword: data; Page 25/50'\n",
      "'SKIPPED PAGE: 25'\n",
      "'Searching jobs... Keyword: data; Page 26/50'\n",
      "'SKIPPED PAGE: 26'\n",
      "'Searching jobs... Keyword: data; Page 27/50'\n",
      "'SKIPPED PAGE: 27'\n",
      "'Searching jobs... Keyword: data; Page 28/50'\n",
      "'SKIPPED PAGE: 28'\n",
      "'Searching jobs... Keyword: data; Page 29/50'\n",
      "'SKIPPED PAGE: 29'\n",
      "'Searching jobs... Keyword: data; Page 30/50'\n",
      "'SKIPPED PAGE: 30'\n",
      "'Searching jobs... Keyword: data; Page 31/50'\n",
      "'SKIPPED PAGE: 31'\n",
      "'Searching jobs... Keyword: data; Page 32/50'\n",
      "'SKIPPED PAGE: 32'\n",
      "'Searching jobs... Keyword: data; Page 33/50'\n",
      "'SKIPPED PAGE: 33'\n",
      "'Searching jobs... Keyword: data; Page 34/50'\n",
      "'SKIPPED PAGE: 34'\n",
      "'Searching jobs... Keyword: data; Page 35/50'\n",
      "'SKIPPED PAGE: 35'\n",
      "'Searching jobs... Keyword: data; Page 36/50'\n",
      "'SKIPPED PAGE: 36'\n",
      "'Searching jobs... Keyword: data; Page 37/50'\n",
      "'SKIPPED PAGE: 37'\n",
      "'Searching jobs... Keyword: data; Page 38/50'\n",
      "'SKIPPED PAGE: 38'\n",
      "'Searching jobs... Keyword: data; Page 39/50'\n",
      "'SKIPPED PAGE: 39'\n",
      "'Searching jobs... Keyword: data; Page 40/50'\n",
      "'SKIPPED PAGE: 40'\n",
      "'Searching jobs... Keyword: data; Page 41/50'\n",
      "'SKIPPED PAGE: 41'\n",
      "'Searching jobs... Keyword: data; Page 42/50'\n",
      "'FINISHED PAGE: 42'\n",
      "'Searching jobs... Keyword: data; Page 43/50'\n",
      "'FINISHED PAGE: 43'\n",
      "'Searching jobs... Keyword: data; Page 44/50'\n",
      "'FINISHED PAGE: 44'\n",
      "'Searching jobs... Keyword: data; Page 45/50'\n",
      "'FINISHED PAGE: 45'\n",
      "'Searching jobs... Keyword: data; Page 46/50'\n",
      "'FINISHED PAGE: 46'\n",
      "'Searching jobs... Keyword: data; Page 47/50'\n",
      "'FINISHED PAGE: 47'\n",
      "'Searching jobs... Keyword: data; Page 48/50'\n",
      "'FINISHED PAGE: 48'\n",
      "'Searching jobs... Keyword: data; Page 49/50'\n",
      "'FINISHED PAGE: 49'\n",
      "'Searching jobs... Keyword: data; Page 50/50'\n",
      "'FINISHED PAGE: 50'\n",
      "CPU times: user 4 s, sys: 792 ms, total: 4.79 s\n",
      "Wall time: 24min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "N_PAGES = 50\n",
    "SEARCH_KEYWORD = \"data\"\n",
    "\n",
    "jobs = []\n",
    "for page_n in range(1, N_PAGES+1):\n",
    "    pprint(f\"Searching jobs... Keyword: {SEARCH_KEYWORD}; Page {page_n}/{N_PAGES}\")\n",
    "    try:\n",
    "        new_batch = job_search.search(SEARCH_KEYWORD, page_n)\n",
    "    except TimeoutException:\n",
    "        pprint(f\"SKIPPED PAGE: {page_n}\")\n",
    "        continue\n",
    "\n",
    "    # Check if the new batch of jobs are duplicates, \n",
    "    # which means we have gone through all the pages and should quit scraping.\n",
    "    if jobs and are_same(new_batch[0], jobs[0]):\n",
    "        pprint(\"Found duplicate results! All the pages have been scraped. Quiting...\")\n",
    "        break\n",
    "        \n",
    "    jobs.extend(new_batch)\n",
    "    pprint(f\"FINISHED PAGE: {page_n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ca956d-a4cb-443d-8d9d-7bbc96e6e4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "500ab9ca-d346-4b90-abb0-fafdffefca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save today's crawl temporarily\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "fname = f\"helsinki_data_jobs_{current_date}.pkl\"\n",
    "with open(f\"../data/tmp/{fname}\", \"wb\") as f:\n",
    "    dicted_jobs = [job.to_dict() for job in jobs]\n",
    "    pickle.dump(dicted_jobs,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22f02c2-cd94-4e16-bb3e-3c3c4b761913",
   "metadata": {},
   "source": [
    "## 2. Scrape job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b17c1166-5c4d-4ee4-a684-10c0535f32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from linkedin_scraper import Job, actions\n",
    "\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class _Job(Job):\n",
    "    def __init__(self, **kwargs):\n",
    "       self.job_title = \"\"\n",
    "       self.required_skills = \"\"\n",
    "       self.job_type_1 = \"\"\n",
    "       self.job_type_2 = \"\"\n",
    " \n",
    "       super().__init__(**kwargs)\n",
    "    \n",
    "    def scrape_logged_in(self, close_on_complete=True):\n",
    "        driver = self.driver\n",
    "        \n",
    "        driver.get(self.linkedin_url)\n",
    "        self.focus()\n",
    "        self.job_title = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'jobs-unified-top-card__job-title')]\").text.strip()\n",
    "        self.company = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-jobs-unified-top-card__primary-description')]//a[1]\").text.strip()\n",
    "        self.company_linkedin_url = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-jobs-unified-top-card__primary-description')]//a\").get_attribute(\"href\")\n",
    "        self.location = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-jobs-unified-top-card__primary-description')]//*\").text.strip()\n",
    "        self.posted_date = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-jobs-unified-top-card__primary-description')]//span[3]\").text.strip()\n",
    "        self.job_type_1 = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'ui-label ui-label--accent-3 text-body-small')]/span\").text.strip()\n",
    "        self.job_description = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'jobs-description')]\").text.strip()\n",
    "        \n",
    "        try:\n",
    "            self.required_skills = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-how-you-match__skills-item')][1]//a\").text.strip()\n",
    "        except TimeoutException as e:\n",
    "            logger.error(str(e))\n",
    "\n",
    "        try:\n",
    "            self.required_skills += self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'job-details-how-you-match__skills-item')][2]//a\").text.strip()\n",
    "        except TimeoutException as e:\n",
    "            logger.error(str(e))\n",
    "\n",
    "        try:\n",
    "            self.job_type_2 = self.wait_for_element_to_load(by=By.XPATH, name=\"(//*[contains(@class, 'ui-label ui-label--accent-3 text-body-small')])[2]/span\").text.strip()\n",
    "        except TimeoutException:\n",
    "            self.job_type_2 = \"\"\n",
    "            \n",
    "        try:\n",
    "            self.applicant_count = self.wait_for_element_to_load(by=By.XPATH, name=\"jobs-unified-top-card__applicant-count\").text.strip()\n",
    "        except TimeoutException:\n",
    "            self.applicant_count = 0\n",
    "        \n",
    "        try:\n",
    "            self.benefits = self.wait_for_element_to_load(by=By.XPATH, name=\"//*[contains(@class, 'salary-main-rail-card')]\").text.strip()\n",
    "        except TimeoutException:\n",
    "            self.benefits = \"\"\n",
    "\n",
    "        if close_on_complete:\n",
    "            driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0690bf7-4c55-434f-a72b-fae89fd21906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "import urllib\n",
    "from time import sleep\n",
    "\n",
    "def set_chrome_options() -> Options:\n",
    "    \"\"\"Sets chrome options for Selenium.\n",
    "    Chrome options for headless browser is enabled.\n",
    "    \"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_prefs = {}\n",
    "    chrome_options.experimental_options[\"prefs\"] = chrome_prefs\n",
    "    chrome_prefs[\"profile.default_content_settings\"] = {\"images\": 2}\n",
    "    return chrome_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b010a69b-bf8d-434e-ba07-641b09ff211c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Logged in.\n"
     ]
    }
   ],
   "source": [
    "# Set up low-level servies for scraping\n",
    "driver = webdriver.Chrome(options=set_chrome_options())\n",
    "actions.login(driver, os.environ[\"EMAIL\"], os.environ[\"PWORD\"]) \n",
    "print(\"... Logged in.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc5236-f815-4a94-b6b4-f0b368132f1e",
   "metadata": {},
   "source": [
    "Ignore the error logs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6b8e6e6-ed7c-4f70-8f48-8e5b463c681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "fname = f\"helsinki_data_jobs_{current_date}.pkl\"\n",
    "\n",
    "with open(f\"../data/tmp/{fname}\", \"rb\") as f:\n",
    "    jobs = pickle.load(f)\n",
    "\n",
    "print(len(jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c10b00c9-d1d6-4723-89a1-7823fd0f4c63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 188/384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55c9a48e24e3 <unknown>\n",
      "#1 0x55c9a4611c76 <unknown>\n",
      "#2 0x55c9a464dc96 <unknown>\n",
      "#3 0x55c9a464ddc1 <unknown>\n",
      "#4 0x55c9a46877f4 <unknown>\n",
      "#5 0x55c9a466d03d <unknown>\n",
      "#6 0x55c9a468530e <unknown>\n",
      "#7 0x55c9a466cde3 <unknown>\n",
      "#8 0x55c9a46422dd <unknown>\n",
      "#9 0x55c9a464334e <unknown>\n",
      "#10 0x55c9a48a23e4 <unknown>\n",
      "#11 0x55c9a48a63d7 <unknown>\n",
      "#12 0x55c9a48b0b20 <unknown>\n",
      "#13 0x55c9a48a7023 <unknown>\n",
      "#14 0x55c9a48751aa <unknown>\n",
      "#15 0x55c9a48cb6b8 <unknown>\n",
      "#16 0x55c9a48cb847 <unknown>\n",
      "#17 0x55c9a48db243 <unknown>\n",
      "#18 0x7f9762694ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 189/384\n",
      "Crawling... Jobs 190/384\n",
      "Crawling... Jobs 191/384\n",
      "Crawling... Jobs 192/384\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n#0 0x55c9a48e24e3 <unknown>\n#1 0x55c9a4611c76 <unknown>\n#2 0x55c9a464dc96 <unknown>\n#3 0x55c9a464ddc1 <unknown>\n#4 0x55c9a46877f4 <unknown>\n#5 0x55c9a466d03d <unknown>\n#6 0x55c9a468530e <unknown>\n#7 0x55c9a466cde3 <unknown>\n#8 0x55c9a46422dd <unknown>\n#9 0x55c9a464334e <unknown>\n#10 0x55c9a48a23e4 <unknown>\n#11 0x55c9a48a63d7 <unknown>\n#12 0x55c9a48b0b20 <unknown>\n#13 0x55c9a48a7023 <unknown>\n#14 0x55c9a48751aa <unknown>\n#15 0x55c9a48cb6b8 <unknown>\n#16 0x55c9a48cb847 <unknown>\n#17 0x55c9a48db243 <unknown>\n#18 0x7f9762694ac3 <unknown>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:10\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m, in \u001b[0;36m_Job.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_type_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_type_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/linkedin_scraper/jobs.py:40\u001b[0m, in \u001b[0;36mJob.__init__\u001b[0;34m(self, linkedin_url, job_title, company, company_linkedin_url, location, posted_date, applicant_count, job_description, benefits, driver, close_on_complete, scrape)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbenefits \u001b[38;5;241m=\u001b[39m benefits\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scrape:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclose_on_complete\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/linkedin_scraper/jobs.py:47\u001b[0m, in \u001b[0;36mJob.scrape\u001b[0;34m(self, close_on_complete)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape\u001b[39m(\u001b[38;5;28mself\u001b[39m, close_on_complete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_signed_in():\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_logged_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclose_on_complete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclose_on_complete\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis part is not implemented yet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m, in \u001b[0;36m_Job.scrape_logged_in\u001b[0;34m(self, close_on_complete)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfocus()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_for_element_to_load(by\u001b[38;5;241m=\u001b[39mBy\u001b[38;5;241m.\u001b[39mXPATH, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//*[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjobs-unified-top-card__job-title\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompany \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_element_to_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//*[contains(@class, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjob-details-jobs-unified-top-card__primary-description\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)]//a[1]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompany_linkedin_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_for_element_to_load(by\u001b[38;5;241m=\u001b[39mBy\u001b[38;5;241m.\u001b[39mXPATH, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//*[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob-details-jobs-unified-top-card__primary-description\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]//a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_for_element_to_load(by\u001b[38;5;241m=\u001b[39mBy\u001b[38;5;241m.\u001b[39mXPATH, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//*[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob-details-jobs-unified-top-card__primary-description\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]//*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/linkedin_scraper/objects.py:82\u001b[0m, in \u001b[0;36mScraper.wait_for_element_to_load\u001b[0;34m(self, by, name, base)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for_element_to_load\u001b[39m(\u001b[38;5;28mself\u001b[39m, by\u001b[38;5;241m=\u001b[39mBy\u001b[38;5;241m.\u001b[39mCLASS_NAME, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpv-top-card\u001b[39m\u001b[38;5;124m\"\u001b[39m, base\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     81\u001b[0m     base \u001b[38;5;241m=\u001b[39m base \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWAIT_FOR_ELEMENT_TIMEOUT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/ds-employment-landscape/.venv/lib/python3.10/site-packages/selenium/webdriver/support/wait.py:95\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n#0 0x55c9a48e24e3 <unknown>\n#1 0x55c9a4611c76 <unknown>\n#2 0x55c9a464dc96 <unknown>\n#3 0x55c9a464ddc1 <unknown>\n#4 0x55c9a46877f4 <unknown>\n#5 0x55c9a466d03d <unknown>\n#6 0x55c9a468530e <unknown>\n#7 0x55c9a466cde3 <unknown>\n#8 0x55c9a46422dd <unknown>\n#9 0x55c9a464334e <unknown>\n#10 0x55c9a48a23e4 <unknown>\n#11 0x55c9a48a63d7 <unknown>\n#12 0x55c9a48b0b20 <unknown>\n#13 0x55c9a48a7023 <unknown>\n#14 0x55c9a48751aa <unknown>\n#15 0x55c9a48cb6b8 <unknown>\n#16 0x55c9a48cb847 <unknown>\n#17 0x55c9a48db243 <unknown>\n#18 0x7f9762694ac3 <unknown>\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException\n",
    "from time import sleep\n",
    "\n",
    "N_JOBS = len(jobs)\n",
    "\n",
    "crawled_jobs = []\n",
    "for i, job in enumerate(jobs):\n",
    "    print(f\"Crawling... Jobs {i+1}/{N_JOBS}\")\n",
    "    try:\n",
    "        _crawled_job = _Job(linkedin_url=job.get(\"linkedin_url\"), driver=driver, close_on_complete=False, scrape=True)\n",
    "        crawled_jobs.append(_crawled_job)\n",
    "        sleep(1)\n",
    "    except StaleElementReferenceException or TimeoutException:\n",
    "        print(f\"... Skipped Job {i+1}/{N_JOBS}.\")\n",
    "        sleep(1)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad0dbf8-cba2-42bc-a496-57345dde2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "260db594-e6f7-4ebc-9294-e132e9ae5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crawled_jobs = pd.DataFrame([vars(job) for job in crawled_jobs]\n",
    "                              ).drop(columns=[\"driver\"]\n",
    "                              ).drop_duplicates(\"linkedin_url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc2d9665-a746-4a98-a1f2-7446de35ac9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>required_skills</th>\n",
       "      <th>job_type_1</th>\n",
       "      <th>job_type_2</th>\n",
       "      <th>linkedin_url</th>\n",
       "      <th>company</th>\n",
       "      <th>company_linkedin_url</th>\n",
       "      <th>location</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>applicant_count</th>\n",
       "      <th>job_description</th>\n",
       "      <th>benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accounts Receivable Accountant</td>\n",
       "      <td>FinnishAccounting, Finance, Infor Enterprise R...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3746211692/...</td>\n",
       "      <td>Walki Group</td>\n",
       "      <td>https://www.linkedin.com/company/walki-group/life</td>\n",
       "      <td>Walki Group · Jakobstad, Ostrobothnia, Finland...</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nWe are looking for an\\nACCOUNTA...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Artificial Intelligence (AI), Cloud Computing,...</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3684400225/...</td>\n",
       "      <td>Cloud1 Oy</td>\n",
       "      <td>https://www.linkedin.com/company/cloud1-oy/life</td>\n",
       "      <td>Cloud1 Oy · Helsinki, Uusimaa, Finland Reposte...</td>\n",
       "      <td>Reposted  3 weeks ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nCloud1 tunnetaan vaativien inte...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Architect</td>\n",
       "      <td>Data Analytics and Data WarehousingData Archit...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3725618198/...</td>\n",
       "      <td>Nortal</td>\n",
       "      <td>https://www.linkedin.com/company/nortal/life</td>\n",
       "      <td>Nortal · Helsinki, Uusimaa, Finland Reposted  ...</td>\n",
       "      <td>Reposted  2 weeks ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nOverview\\n\\nDo you enjoy being ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ETL Specialist</td>\n",
       "      <td>Data Warehousing, English, Extract, Transform,...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3743271896/...</td>\n",
       "      <td>Gazelle Global</td>\n",
       "      <td>https://www.linkedin.com/company/gazelle-globa...</td>\n",
       "      <td>Gazelle Global · Helsinki, Uusimaa, Finland  1...</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nETL Specialist\\n\\n A great oppo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Specialist, Data Protection</td>\n",
       "      <td>DatabasesCommunication, Data Modeling, Data Pr...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3754374323/...</td>\n",
       "      <td>VTT</td>\n",
       "      <td>https://www.linkedin.com/company/vtt/life</td>\n",
       "      <td>VTT · Espoo, Uusimaa, Finland  1 day ago  · 2 ...</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nAre you looking for a new oppor...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Internal Audit Manager, Model Risk</td>\n",
       "      <td>Communication, Communication Training, Diploma...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3744389039/...</td>\n",
       "      <td>Nordea</td>\n",
       "      <td>https://www.linkedin.com/company/nordea/life</td>\n",
       "      <td>Nordea · Helsinki, Uusimaa, Finland Reposted  ...</td>\n",
       "      <td>Reposted  4 days ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nJob ID: 10821 \\n #GIA #modelris...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Senior IT Security Specialist</td>\n",
       "      <td>Application Security, Communication, Cyberark,...</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3739448796/...</td>\n",
       "      <td>Nordea</td>\n",
       "      <td>https://www.linkedin.com/company/nordea/life</td>\n",
       "      <td>Nordea · Helsinki, Uusimaa, Finland  1 week ag...</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nJob ID:19983 \\n Would you like ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Senior Cloud Platform Engineer (FinOps)</td>\n",
       "      <td>Analytical Skills and Cloud ComputingBudgeting...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td></td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3720773085/...</td>\n",
       "      <td>AlphaSense</td>\n",
       "      <td>https://www.linkedin.com/company/alphasense/life</td>\n",
       "      <td>AlphaSense · Helsinki, Uusimaa, Finland Repost...</td>\n",
       "      <td>Reposted  4 hours ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nAbout AlphaSense\\n\\nAlphaSense ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Senior Engineering Director (Infrastructure)</td>\n",
       "      <td>Cloud ComputingBudget Management, Budgeting, C...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3730268828/...</td>\n",
       "      <td>Supermetrics</td>\n",
       "      <td>https://www.linkedin.com/company/supermetrics/...</td>\n",
       "      <td>Supermetrics · Helsinki, Uusimaa, Finland Repo...</td>\n",
       "      <td>Reposted  1 week ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nWould you like to work with a t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Product Lead, Consumer Search</td>\n",
       "      <td>Analytical Skills, Analytics, Data Analysis, D...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3738358575/...</td>\n",
       "      <td>Wolt</td>\n",
       "      <td>https://www.linkedin.com/company/wolt-oy/life</td>\n",
       "      <td>Wolt · Helsinki, Uusimaa, Finland  2 weeks ago...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nJob Description\\n\\nWe are looki...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        job_title  \\\n",
       "0                  Accounts Receivable Accountant   \n",
       "1                             Azure Data Engineer   \n",
       "2                                  Data Architect   \n",
       "3                                  ETL Specialist   \n",
       "4                     Specialist, Data Protection   \n",
       "..                                            ...   \n",
       "186            Internal Audit Manager, Model Risk   \n",
       "187                 Senior IT Security Specialist   \n",
       "188       Senior Cloud Platform Engineer (FinOps)   \n",
       "189  Senior Engineering Director (Infrastructure)   \n",
       "190                 Product Lead, Consumer Search   \n",
       "\n",
       "                                       required_skills job_type_1 job_type_2  \\\n",
       "0    FinnishAccounting, Finance, Infor Enterprise R...     Hybrid  Full-time   \n",
       "1    Artificial Intelligence (AI), Cloud Computing,...    On-site  Full-time   \n",
       "2    Data Analytics and Data WarehousingData Archit...     Hybrid  Full-time   \n",
       "3    Data Warehousing, English, Extract, Transform,...     Hybrid  Full-time   \n",
       "4    DatabasesCommunication, Data Modeling, Data Pr...     Hybrid  Full-time   \n",
       "..                                                 ...        ...        ...   \n",
       "186  Communication, Communication Training, Diploma...     Hybrid  Full-time   \n",
       "187  Application Security, Communication, Cyberark,...    On-site  Full-time   \n",
       "188  Analytical Skills and Cloud ComputingBudgeting...  Full-time              \n",
       "189  Cloud ComputingBudget Management, Budgeting, C...     Hybrid  Full-time   \n",
       "190  Analytical Skills, Analytics, Data Analysis, D...     Remote  Full-time   \n",
       "\n",
       "                                          linkedin_url         company  \\\n",
       "0    https://www.linkedin.com/jobs/view/3746211692/...     Walki Group   \n",
       "1    https://www.linkedin.com/jobs/view/3684400225/...       Cloud1 Oy   \n",
       "2    https://www.linkedin.com/jobs/view/3725618198/...          Nortal   \n",
       "3    https://www.linkedin.com/jobs/view/3743271896/...  Gazelle Global   \n",
       "4    https://www.linkedin.com/jobs/view/3754374323/...             VTT   \n",
       "..                                                 ...             ...   \n",
       "186  https://www.linkedin.com/jobs/view/3744389039/...          Nordea   \n",
       "187  https://www.linkedin.com/jobs/view/3739448796/...          Nordea   \n",
       "188  https://www.linkedin.com/jobs/view/3720773085/...      AlphaSense   \n",
       "189  https://www.linkedin.com/jobs/view/3730268828/...    Supermetrics   \n",
       "190  https://www.linkedin.com/jobs/view/3738358575/...            Wolt   \n",
       "\n",
       "                                  company_linkedin_url  \\\n",
       "0    https://www.linkedin.com/company/walki-group/life   \n",
       "1      https://www.linkedin.com/company/cloud1-oy/life   \n",
       "2         https://www.linkedin.com/company/nortal/life   \n",
       "3    https://www.linkedin.com/company/gazelle-globa...   \n",
       "4            https://www.linkedin.com/company/vtt/life   \n",
       "..                                                 ...   \n",
       "186       https://www.linkedin.com/company/nordea/life   \n",
       "187       https://www.linkedin.com/company/nordea/life   \n",
       "188   https://www.linkedin.com/company/alphasense/life   \n",
       "189  https://www.linkedin.com/company/supermetrics/...   \n",
       "190      https://www.linkedin.com/company/wolt-oy/life   \n",
       "\n",
       "                                              location            posted_date  \\\n",
       "0    Walki Group · Jakobstad, Ostrobothnia, Finland...             6 days ago   \n",
       "1    Cloud1 Oy · Helsinki, Uusimaa, Finland Reposte...  Reposted  3 weeks ago   \n",
       "2    Nortal · Helsinki, Uusimaa, Finland Reposted  ...  Reposted  2 weeks ago   \n",
       "3    Gazelle Global · Helsinki, Uusimaa, Finland  1...             1 week ago   \n",
       "4    VTT · Espoo, Uusimaa, Finland  1 day ago  · 2 ...              1 day ago   \n",
       "..                                                 ...                    ...   \n",
       "186  Nordea · Helsinki, Uusimaa, Finland Reposted  ...   Reposted  4 days ago   \n",
       "187  Nordea · Helsinki, Uusimaa, Finland  1 week ag...             1 week ago   \n",
       "188  AlphaSense · Helsinki, Uusimaa, Finland Repost...  Reposted  4 hours ago   \n",
       "189  Supermetrics · Helsinki, Uusimaa, Finland Repo...   Reposted  1 week ago   \n",
       "190  Wolt · Helsinki, Uusimaa, Finland  2 weeks ago...            2 weeks ago   \n",
       "\n",
       "     applicant_count                                    job_description  \\\n",
       "0                  0  About the job\\nWe are looking for an\\nACCOUNTA...   \n",
       "1                  0  About the job\\nCloud1 tunnetaan vaativien inte...   \n",
       "2                  0  About the job\\nOverview\\n\\nDo you enjoy being ...   \n",
       "3                  0  About the job\\nETL Specialist\\n\\n A great oppo...   \n",
       "4                  0  About the job\\nAre you looking for a new oppor...   \n",
       "..               ...                                                ...   \n",
       "186                0  About the job\\nJob ID: 10821 \\n #GIA #modelris...   \n",
       "187                0  About the job\\nJob ID:19983 \\n Would you like ...   \n",
       "188                0  About the job\\nAbout AlphaSense\\n\\nAlphaSense ...   \n",
       "189                0  About the job\\nWould you like to work with a t...   \n",
       "190                0  About the job\\nJob Description\\n\\nWe are looki...   \n",
       "\n",
       "    benefits  \n",
       "0             \n",
       "1             \n",
       "2             \n",
       "3             \n",
       "4             \n",
       "..       ...  \n",
       "186           \n",
       "187           \n",
       "188           \n",
       "189           \n",
       "190           \n",
       "\n",
       "[191 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crawled_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b58dfc6-3ab7-416e-834f-525cb464aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_crawled_jobs.to_csv(f\"../data/crawled_jobs_1-{len(crawled_jobs}_checkpoint.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568898a5-df54-4afa-85ff-3b858f901e30",
   "metadata": {},
   "source": [
    "### 2.1 Continue from the failed point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e352c75e-aaa9-4bd8-ac86-add24d96cdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Logged in.\n"
     ]
    }
   ],
   "source": [
    "# In case session expiration\n",
    "driver = webdriver.Chrome(options=set_chrome_options())\n",
    "actions.login(driver, os.environ[\"EMAIL\"], os.environ[\"PWORD\"]) \n",
    "print(\"... Logged in.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50eff973-e5db-40c0-9a73-24e02e836e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 305/384\n",
      "Crawling... Jobs 306/384\n",
      "Crawling... Jobs 307/384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55c9a48e24e3 <unknown>\n",
      "#1 0x55c9a4611c76 <unknown>\n",
      "#2 0x55c9a464dc96 <unknown>\n",
      "#3 0x55c9a464ddc1 <unknown>\n",
      "#4 0x55c9a46877f4 <unknown>\n",
      "#5 0x55c9a466d03d <unknown>\n",
      "#6 0x55c9a468530e <unknown>\n",
      "#7 0x55c9a466cde3 <unknown>\n",
      "#8 0x55c9a46422dd <unknown>\n",
      "#9 0x55c9a464334e <unknown>\n",
      "#10 0x55c9a48a23e4 <unknown>\n",
      "#11 0x55c9a48a63d7 <unknown>\n",
      "#12 0x55c9a48b0b20 <unknown>\n",
      "#13 0x55c9a48a7023 <unknown>\n",
      "#14 0x55c9a48751aa <unknown>\n",
      "#15 0x55c9a48cb6b8 <unknown>\n",
      "#16 0x55c9a48cb847 <unknown>\n",
      "#17 0x55c9a48db243 <unknown>\n",
      "#18 0x7f9762694ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 308/384\n",
      "Crawling... Jobs 309/384\n",
      "Crawling... Jobs 310/384\n",
      "Crawling... Jobs 311/384\n",
      "Crawling... Jobs 312/384\n",
      "Crawling... Jobs 313/384\n",
      "Crawling... Jobs 314/384\n",
      "Crawling... Jobs 315/384\n",
      "Crawling... Jobs 316/384\n",
      "Crawling... Jobs 317/384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55c9a48e24e3 <unknown>\n",
      "#1 0x55c9a4611c76 <unknown>\n",
      "#2 0x55c9a464dc96 <unknown>\n",
      "#3 0x55c9a464ddc1 <unknown>\n",
      "#4 0x55c9a46877f4 <unknown>\n",
      "#5 0x55c9a466d03d <unknown>\n",
      "#6 0x55c9a468530e <unknown>\n",
      "#7 0x55c9a466cde3 <unknown>\n",
      "#8 0x55c9a46422dd <unknown>\n",
      "#9 0x55c9a464334e <unknown>\n",
      "#10 0x55c9a48a23e4 <unknown>\n",
      "#11 0x55c9a48a63d7 <unknown>\n",
      "#12 0x55c9a48b0b20 <unknown>\n",
      "#13 0x55c9a48a7023 <unknown>\n",
      "#14 0x55c9a48751aa <unknown>\n",
      "#15 0x55c9a48cb6b8 <unknown>\n",
      "#16 0x55c9a48cb847 <unknown>\n",
      "#17 0x55c9a48db243 <unknown>\n",
      "#18 0x7f9762694ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 318/384\n",
      "Crawling... Jobs 319/384\n",
      "Crawling... Jobs 320/384\n",
      "Crawling... Jobs 321/384\n",
      "Crawling... Jobs 322/384\n",
      "Crawling... Jobs 323/384\n",
      "Crawling... Jobs 324/384\n",
      "Crawling... Jobs 325/384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55c9a48e24e3 <unknown>\n",
      "#1 0x55c9a4611c76 <unknown>\n",
      "#2 0x55c9a464dc96 <unknown>\n",
      "#3 0x55c9a464ddc1 <unknown>\n",
      "#4 0x55c9a46877f4 <unknown>\n",
      "#5 0x55c9a466d03d <unknown>\n",
      "#6 0x55c9a468530e <unknown>\n",
      "#7 0x55c9a466cde3 <unknown>\n",
      "#8 0x55c9a46422dd <unknown>\n",
      "#9 0x55c9a464334e <unknown>\n",
      "#10 0x55c9a48a23e4 <unknown>\n",
      "#11 0x55c9a48a63d7 <unknown>\n",
      "#12 0x55c9a48b0b20 <unknown>\n",
      "#13 0x55c9a48a7023 <unknown>\n",
      "#14 0x55c9a48751aa <unknown>\n",
      "#15 0x55c9a48cb6b8 <unknown>\n",
      "#16 0x55c9a48cb847 <unknown>\n",
      "#17 0x55c9a48db243 <unknown>\n",
      "#18 0x7f9762694ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 326/384\n",
      "Crawling... Jobs 327/384\n",
      "Crawling... Jobs 328/384\n",
      "Crawling... Jobs 329/384\n",
      "Crawling... Jobs 330/384\n",
      "Crawling... Jobs 331/384\n",
      "Crawling... Jobs 332/384\n",
      "Crawling... Jobs 333/384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55c9a48e24e3 <unknown>\n",
      "#1 0x55c9a4611c76 <unknown>\n",
      "#2 0x55c9a464dc96 <unknown>\n",
      "#3 0x55c9a464ddc1 <unknown>\n",
      "#4 0x55c9a46877f4 <unknown>\n",
      "#5 0x55c9a466d03d <unknown>\n",
      "#6 0x55c9a468530e <unknown>\n",
      "#7 0x55c9a466cde3 <unknown>\n",
      "#8 0x55c9a46422dd <unknown>\n",
      "#9 0x55c9a464334e <unknown>\n",
      "#10 0x55c9a48a23e4 <unknown>\n",
      "#11 0x55c9a48a63d7 <unknown>\n",
      "#12 0x55c9a48b0b20 <unknown>\n",
      "#13 0x55c9a48a7023 <unknown>\n",
      "#14 0x55c9a48751aa <unknown>\n",
      "#15 0x55c9a48cb6b8 <unknown>\n",
      "#16 0x55c9a48cb847 <unknown>\n",
      "#17 0x55c9a48db243 <unknown>\n",
      "#18 0x7f9762694ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 334/384\n",
      "Crawling... Jobs 335/384\n",
      "Crawling... Jobs 336/384\n",
      "Crawling... Jobs 337/384\n",
      "Crawling... Jobs 338/384\n",
      "Crawling... Jobs 339/384\n",
      "Crawling... Jobs 340/384\n",
      "Crawling... Jobs 341/384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55c9a48e24e3 <unknown>\n",
      "#1 0x55c9a4611c76 <unknown>\n",
      "#2 0x55c9a464dc96 <unknown>\n",
      "#3 0x55c9a464ddc1 <unknown>\n",
      "#4 0x55c9a46877f4 <unknown>\n",
      "#5 0x55c9a466d03d <unknown>\n",
      "#6 0x55c9a468530e <unknown>\n",
      "#7 0x55c9a466cde3 <unknown>\n",
      "#8 0x55c9a46422dd <unknown>\n",
      "#9 0x55c9a464334e <unknown>\n",
      "#10 0x55c9a48a23e4 <unknown>\n",
      "#11 0x55c9a48a63d7 <unknown>\n",
      "#12 0x55c9a48b0b20 <unknown>\n",
      "#13 0x55c9a48a7023 <unknown>\n",
      "#14 0x55c9a48751aa <unknown>\n",
      "#15 0x55c9a48cb6b8 <unknown>\n",
      "#16 0x55c9a48cb847 <unknown>\n",
      "#17 0x55c9a48db243 <unknown>\n",
      "#18 0x7f9762694ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 342/384\n",
      "Crawling... Jobs 343/384\n",
      "Crawling... Jobs 344/384\n",
      "Crawling... Jobs 345/384\n",
      "Crawling... Jobs 346/384\n",
      "Crawling... Jobs 347/384\n",
      "Crawling... Jobs 348/384\n",
      "Crawling... Jobs 349/384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55c9a48e24e3 <unknown>\n",
      "#1 0x55c9a4611c76 <unknown>\n",
      "#2 0x55c9a464dc96 <unknown>\n",
      "#3 0x55c9a464ddc1 <unknown>\n",
      "#4 0x55c9a46877f4 <unknown>\n",
      "#5 0x55c9a466d03d <unknown>\n",
      "#6 0x55c9a468530e <unknown>\n",
      "#7 0x55c9a466cde3 <unknown>\n",
      "#8 0x55c9a46422dd <unknown>\n",
      "#9 0x55c9a464334e <unknown>\n",
      "#10 0x55c9a48a23e4 <unknown>\n",
      "#11 0x55c9a48a63d7 <unknown>\n",
      "#12 0x55c9a48b0b20 <unknown>\n",
      "#13 0x55c9a48a7023 <unknown>\n",
      "#14 0x55c9a48751aa <unknown>\n",
      "#15 0x55c9a48cb6b8 <unknown>\n",
      "#16 0x55c9a48cb847 <unknown>\n",
      "#17 0x55c9a48db243 <unknown>\n",
      "#18 0x7f9762694ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 350/384\n",
      "Crawling... Jobs 351/384\n",
      "Crawling... Jobs 352/384\n",
      "Crawling... Jobs 353/384\n",
      "Crawling... Jobs 354/384\n",
      "Crawling... Jobs 355/384\n",
      "Crawling... Jobs 356/384\n",
      "Crawling... Jobs 357/384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55c9a48e24e3 <unknown>\n",
      "#1 0x55c9a4611c76 <unknown>\n",
      "#2 0x55c9a464dc96 <unknown>\n",
      "#3 0x55c9a464ddc1 <unknown>\n",
      "#4 0x55c9a46877f4 <unknown>\n",
      "#5 0x55c9a466d03d <unknown>\n",
      "#6 0x55c9a468530e <unknown>\n",
      "#7 0x55c9a466cde3 <unknown>\n",
      "#8 0x55c9a46422dd <unknown>\n",
      "#9 0x55c9a464334e <unknown>\n",
      "#10 0x55c9a48a23e4 <unknown>\n",
      "#11 0x55c9a48a63d7 <unknown>\n",
      "#12 0x55c9a48b0b20 <unknown>\n",
      "#13 0x55c9a48a7023 <unknown>\n",
      "#14 0x55c9a48751aa <unknown>\n",
      "#15 0x55c9a48cb6b8 <unknown>\n",
      "#16 0x55c9a48cb847 <unknown>\n",
      "#17 0x55c9a48db243 <unknown>\n",
      "#18 0x7f9762694ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 358/384\n",
      "Crawling... Jobs 359/384\n",
      "Crawling... Jobs 360/384\n",
      "Crawling... Jobs 361/384\n",
      "Crawling... Jobs 362/384\n",
      "Crawling... Jobs 363/384\n",
      "Crawling... Jobs 364/384\n",
      "Crawling... Jobs 365/384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55c9a48e24e3 <unknown>\n",
      "#1 0x55c9a4611c76 <unknown>\n",
      "#2 0x55c9a464dc96 <unknown>\n",
      "#3 0x55c9a464ddc1 <unknown>\n",
      "#4 0x55c9a46877f4 <unknown>\n",
      "#5 0x55c9a466d03d <unknown>\n",
      "#6 0x55c9a468530e <unknown>\n",
      "#7 0x55c9a466cde3 <unknown>\n",
      "#8 0x55c9a46422dd <unknown>\n",
      "#9 0x55c9a464334e <unknown>\n",
      "#10 0x55c9a48a23e4 <unknown>\n",
      "#11 0x55c9a48a63d7 <unknown>\n",
      "#12 0x55c9a48b0b20 <unknown>\n",
      "#13 0x55c9a48a7023 <unknown>\n",
      "#14 0x55c9a48751aa <unknown>\n",
      "#15 0x55c9a48cb6b8 <unknown>\n",
      "#16 0x55c9a48cb847 <unknown>\n",
      "#17 0x55c9a48db243 <unknown>\n",
      "#18 0x7f9762694ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 366/384\n",
      "Crawling... Jobs 367/384\n",
      "Crawling... Jobs 368/384\n",
      "Crawling... Jobs 369/384\n",
      "Crawling... Jobs 370/384\n",
      "Crawling... Jobs 371/384\n",
      "Crawling... Jobs 372/384\n",
      "Crawling... Jobs 373/384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55c9a48e24e3 <unknown>\n",
      "#1 0x55c9a4611c76 <unknown>\n",
      "#2 0x55c9a464dc96 <unknown>\n",
      "#3 0x55c9a464ddc1 <unknown>\n",
      "#4 0x55c9a46877f4 <unknown>\n",
      "#5 0x55c9a466d03d <unknown>\n",
      "#6 0x55c9a468530e <unknown>\n",
      "#7 0x55c9a466cde3 <unknown>\n",
      "#8 0x55c9a46422dd <unknown>\n",
      "#9 0x55c9a464334e <unknown>\n",
      "#10 0x55c9a48a23e4 <unknown>\n",
      "#11 0x55c9a48a63d7 <unknown>\n",
      "#12 0x55c9a48b0b20 <unknown>\n",
      "#13 0x55c9a48a7023 <unknown>\n",
      "#14 0x55c9a48751aa <unknown>\n",
      "#15 0x55c9a48cb6b8 <unknown>\n",
      "#16 0x55c9a48cb847 <unknown>\n",
      "#17 0x55c9a48db243 <unknown>\n",
      "#18 0x7f9762694ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 374/384\n",
      "Crawling... Jobs 375/384\n",
      "Crawling... Jobs 376/384\n",
      "Crawling... Jobs 377/384\n",
      "Crawling... Jobs 378/384\n",
      "Crawling... Jobs 379/384\n",
      "Crawling... Jobs 380/384\n",
      "Crawling... Jobs 381/384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Message: \n",
      "Stacktrace:\n",
      "#0 0x55c9a48e24e3 <unknown>\n",
      "#1 0x55c9a4611c76 <unknown>\n",
      "#2 0x55c9a464dc96 <unknown>\n",
      "#3 0x55c9a464ddc1 <unknown>\n",
      "#4 0x55c9a46877f4 <unknown>\n",
      "#5 0x55c9a466d03d <unknown>\n",
      "#6 0x55c9a468530e <unknown>\n",
      "#7 0x55c9a466cde3 <unknown>\n",
      "#8 0x55c9a46422dd <unknown>\n",
      "#9 0x55c9a464334e <unknown>\n",
      "#10 0x55c9a48a23e4 <unknown>\n",
      "#11 0x55c9a48a63d7 <unknown>\n",
      "#12 0x55c9a48b0b20 <unknown>\n",
      "#13 0x55c9a48a7023 <unknown>\n",
      "#14 0x55c9a48751aa <unknown>\n",
      "#15 0x55c9a48cb6b8 <unknown>\n",
      "#16 0x55c9a48cb847 <unknown>\n",
      "#17 0x55c9a48db243 <unknown>\n",
      "#18 0x7f9762694ac3 <unknown>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling... Jobs 382/384\n",
      "Crawling... Jobs 383/384\n",
      "Crawling... Jobs 384/384\n",
      "CPU times: user 9.57 s, sys: 1.79 s, total: 11.4 s\n",
      "Wall time: 49min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Continue\n",
    "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException\n",
    "\n",
    "CONTINUE_FROM = 193\n",
    "\n",
    "for i, job in enumerate(jobs):\n",
    "    if i+1<CONTINUE_FROM:\n",
    "        continue\n",
    "        \n",
    "    print(f\"Crawling... Jobs {i+1}/{N_JOBS}\")\n",
    "    try:\n",
    "        _crawled_job = _Job(linkedin_url=job.get(\"linkedin_url\"), driver=driver, close_on_complete=False, scrape=True)\n",
    "        crawled_jobs.append(_crawled_job)\n",
    "        sleep(1)\n",
    "    except StaleElementReferenceException or TimeoutException:\n",
    "        print(f\"... Skipped Job {i+1}/{N_JOBS}.\")\n",
    "        sleep(1)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f3595eb-d170-4e5a-b7d3-d86b8480a281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>required_skills</th>\n",
       "      <th>job_type_1</th>\n",
       "      <th>job_type_2</th>\n",
       "      <th>linkedin_url</th>\n",
       "      <th>company</th>\n",
       "      <th>company_linkedin_url</th>\n",
       "      <th>location</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>applicant_count</th>\n",
       "      <th>job_description</th>\n",
       "      <th>benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accounts Receivable Accountant</td>\n",
       "      <td>FinnishAccounting, Finance, Infor Enterprise R...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3746211692/...</td>\n",
       "      <td>Walki Group</td>\n",
       "      <td>https://www.linkedin.com/company/walki-group/life</td>\n",
       "      <td>Walki Group · Jakobstad, Ostrobothnia, Finland...</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nWe are looking for an\\nACCOUNTA...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Artificial Intelligence (AI), Cloud Computing,...</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3684400225/...</td>\n",
       "      <td>Cloud1 Oy</td>\n",
       "      <td>https://www.linkedin.com/company/cloud1-oy/life</td>\n",
       "      <td>Cloud1 Oy · Helsinki, Uusimaa, Finland Reposte...</td>\n",
       "      <td>Reposted  3 weeks ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nCloud1 tunnetaan vaativien inte...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Architect</td>\n",
       "      <td>Data Analytics and Data WarehousingData Archit...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3725618198/...</td>\n",
       "      <td>Nortal</td>\n",
       "      <td>https://www.linkedin.com/company/nortal/life</td>\n",
       "      <td>Nortal · Helsinki, Uusimaa, Finland Reposted  ...</td>\n",
       "      <td>Reposted  2 weeks ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nOverview\\n\\nDo you enjoy being ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ETL Specialist</td>\n",
       "      <td>Data Warehousing, English, Extract, Transform,...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3743271896/...</td>\n",
       "      <td>Gazelle Global</td>\n",
       "      <td>https://www.linkedin.com/company/gazelle-globa...</td>\n",
       "      <td>Gazelle Global · Helsinki, Uusimaa, Finland  1...</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nETL Specialist\\n\\n A great oppo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Specialist, Data Protection</td>\n",
       "      <td>DatabasesCommunication, Data Modeling, Data Pr...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3754374323/...</td>\n",
       "      <td>VTT</td>\n",
       "      <td>https://www.linkedin.com/company/vtt/life</td>\n",
       "      <td>VTT · Espoo, Uusimaa, Finland  1 day ago  · 2 ...</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nAre you looking for a new oppor...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>(Senior) Data Engineer - Tietoevry Tech Services</td>\n",
       "      <td>Analytics, Data Analytics, Data Engineering, D...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3717016713/...</td>\n",
       "      <td>Tietoevry</td>\n",
       "      <td>https://www.linkedin.com/company/tietoevry/life</td>\n",
       "      <td>Tietoevry · Espoo, Uusimaa, Finland Reposted  ...</td>\n",
       "      <td>Reposted  4 days ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nYou may apply to Tietoevry by s...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>(Senior) Quantitative Risk Analyst (Data Analy...</td>\n",
       "      <td>Business Requirements, Credit Risk Management,...</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3733080582/...</td>\n",
       "      <td>Nordea</td>\n",
       "      <td>https://www.linkedin.com/company/nordea/life</td>\n",
       "      <td>Nordea · Helsinki, Uusimaa, Finland  2 weeks a...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nJob ID: 17007 \\nWe are looking ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Artificial Intelligence (AI), Cloud Computing,...</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3684400225/...</td>\n",
       "      <td>Cloud1 Oy</td>\n",
       "      <td>https://www.linkedin.com/company/cloud1-oy/life</td>\n",
       "      <td>Cloud1 Oy · Helsinki, Uusimaa, Finland Reposte...</td>\n",
       "      <td>Reposted  3 weeks ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nCloud1 tunnetaan vaativien inte...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Data Engineer, OP Life Insurance</td>\n",
       "      <td>Data Analytics, Data Engineering, Data Warehou...</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3749553229/...</td>\n",
       "      <td>OP Financial Group</td>\n",
       "      <td>https://www.linkedin.com/company/op-financial-...</td>\n",
       "      <td>OP Financial Group · Helsinki, Uusimaa, Finlan...</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nAre you ready to embark on an e...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Senior Cloud Platform Engineer (Data Management)</td>\n",
       "      <td>Databases, Google Cloud Platform (GCP), and Mi...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td></td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3727082911/...</td>\n",
       "      <td>AlphaSense</td>\n",
       "      <td>https://www.linkedin.com/company/alphasense/life</td>\n",
       "      <td>AlphaSense · Helsinki, Uusimaa, Finland Repost...</td>\n",
       "      <td>Reposted  1 week ago</td>\n",
       "      <td>0</td>\n",
       "      <td>About the job\\nAbout AlphaSense\\n\\nAlphaSense ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title  \\\n",
       "0                       Accounts Receivable Accountant   \n",
       "1                                  Azure Data Engineer   \n",
       "2                                       Data Architect   \n",
       "3                                       ETL Specialist   \n",
       "4                          Specialist, Data Protection   \n",
       "..                                                 ...   \n",
       "378   (Senior) Data Engineer - Tietoevry Tech Services   \n",
       "379  (Senior) Quantitative Risk Analyst (Data Analy...   \n",
       "380                                Azure Data Engineer   \n",
       "381                   Data Engineer, OP Life Insurance   \n",
       "382   Senior Cloud Platform Engineer (Data Management)   \n",
       "\n",
       "                                       required_skills job_type_1 job_type_2  \\\n",
       "0    FinnishAccounting, Finance, Infor Enterprise R...     Hybrid  Full-time   \n",
       "1    Artificial Intelligence (AI), Cloud Computing,...    On-site  Full-time   \n",
       "2    Data Analytics and Data WarehousingData Archit...     Hybrid  Full-time   \n",
       "3    Data Warehousing, English, Extract, Transform,...     Hybrid  Full-time   \n",
       "4    DatabasesCommunication, Data Modeling, Data Pr...     Hybrid  Full-time   \n",
       "..                                                 ...        ...        ...   \n",
       "378  Analytics, Data Analytics, Data Engineering, D...     Hybrid  Full-time   \n",
       "379  Business Requirements, Credit Risk Management,...    On-site  Full-time   \n",
       "380  Artificial Intelligence (AI), Cloud Computing,...    On-site  Full-time   \n",
       "381  Data Analytics, Data Engineering, Data Warehou...     Hybrid  Full-time   \n",
       "382  Databases, Google Cloud Platform (GCP), and Mi...  Full-time              \n",
       "\n",
       "                                          linkedin_url             company  \\\n",
       "0    https://www.linkedin.com/jobs/view/3746211692/...         Walki Group   \n",
       "1    https://www.linkedin.com/jobs/view/3684400225/...           Cloud1 Oy   \n",
       "2    https://www.linkedin.com/jobs/view/3725618198/...              Nortal   \n",
       "3    https://www.linkedin.com/jobs/view/3743271896/...      Gazelle Global   \n",
       "4    https://www.linkedin.com/jobs/view/3754374323/...                 VTT   \n",
       "..                                                 ...                 ...   \n",
       "378  https://www.linkedin.com/jobs/view/3717016713/...           Tietoevry   \n",
       "379  https://www.linkedin.com/jobs/view/3733080582/...              Nordea   \n",
       "380  https://www.linkedin.com/jobs/view/3684400225/...           Cloud1 Oy   \n",
       "381  https://www.linkedin.com/jobs/view/3749553229/...  OP Financial Group   \n",
       "382  https://www.linkedin.com/jobs/view/3727082911/...          AlphaSense   \n",
       "\n",
       "                                  company_linkedin_url  \\\n",
       "0    https://www.linkedin.com/company/walki-group/life   \n",
       "1      https://www.linkedin.com/company/cloud1-oy/life   \n",
       "2         https://www.linkedin.com/company/nortal/life   \n",
       "3    https://www.linkedin.com/company/gazelle-globa...   \n",
       "4            https://www.linkedin.com/company/vtt/life   \n",
       "..                                                 ...   \n",
       "378    https://www.linkedin.com/company/tietoevry/life   \n",
       "379       https://www.linkedin.com/company/nordea/life   \n",
       "380    https://www.linkedin.com/company/cloud1-oy/life   \n",
       "381  https://www.linkedin.com/company/op-financial-...   \n",
       "382   https://www.linkedin.com/company/alphasense/life   \n",
       "\n",
       "                                              location            posted_date  \\\n",
       "0    Walki Group · Jakobstad, Ostrobothnia, Finland...             6 days ago   \n",
       "1    Cloud1 Oy · Helsinki, Uusimaa, Finland Reposte...  Reposted  3 weeks ago   \n",
       "2    Nortal · Helsinki, Uusimaa, Finland Reposted  ...  Reposted  2 weeks ago   \n",
       "3    Gazelle Global · Helsinki, Uusimaa, Finland  1...             1 week ago   \n",
       "4    VTT · Espoo, Uusimaa, Finland  1 day ago  · 2 ...              1 day ago   \n",
       "..                                                 ...                    ...   \n",
       "378  Tietoevry · Espoo, Uusimaa, Finland Reposted  ...   Reposted  4 days ago   \n",
       "379  Nordea · Helsinki, Uusimaa, Finland  2 weeks a...            2 weeks ago   \n",
       "380  Cloud1 Oy · Helsinki, Uusimaa, Finland Reposte...  Reposted  3 weeks ago   \n",
       "381  OP Financial Group · Helsinki, Uusimaa, Finlan...             5 days ago   \n",
       "382  AlphaSense · Helsinki, Uusimaa, Finland Repost...   Reposted  1 week ago   \n",
       "\n",
       "     applicant_count                                    job_description  \\\n",
       "0                  0  About the job\\nWe are looking for an\\nACCOUNTA...   \n",
       "1                  0  About the job\\nCloud1 tunnetaan vaativien inte...   \n",
       "2                  0  About the job\\nOverview\\n\\nDo you enjoy being ...   \n",
       "3                  0  About the job\\nETL Specialist\\n\\n A great oppo...   \n",
       "4                  0  About the job\\nAre you looking for a new oppor...   \n",
       "..               ...                                                ...   \n",
       "378                0  About the job\\nYou may apply to Tietoevry by s...   \n",
       "379                0  About the job\\nJob ID: 17007 \\nWe are looking ...   \n",
       "380                0  About the job\\nCloud1 tunnetaan vaativien inte...   \n",
       "381                0  About the job\\nAre you ready to embark on an e...   \n",
       "382                0  About the job\\nAbout AlphaSense\\n\\nAlphaSense ...   \n",
       "\n",
       "    benefits  \n",
       "0             \n",
       "1             \n",
       "2             \n",
       "3             \n",
       "4             \n",
       "..       ...  \n",
       "378           \n",
       "379           \n",
       "380           \n",
       "381           \n",
       "382           \n",
       "\n",
       "[383 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crawled_jobs = pd.DataFrame([vars(job) for job in crawled_jobs]).drop(columns=[\"driver\"]).drop_duplicates(\"linkedin_url\")\n",
    "df_crawled_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bf2bda0-7b3c-425d-87a4-0420c1e45d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save today's crawl\n",
    "import datetime\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "fname = f\"../data/crawled_jobs_{current_date}.csv\"\n",
    "\n",
    "df_crawled_jobs.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb0d8b-2cb2-4217-ab99-6ece5a995d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a94094-a7ba-4dd8-96d6-17b734384714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
